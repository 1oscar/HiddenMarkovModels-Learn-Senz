Hidden Markov Model for Senz+
===

简介
---
用户情景的变化可以看作一个隐马尔科夫链模型，这些我们事先定义好的用户情景就是这个马尔科夫链中的隐状态，
用户情景客观存在（例如用户正在旅游、正在购物等等是客观存在的事实），用户在这些情景中以一定的转移概率跳转，
只是我们作为app开发者是无法观测到的。用户在某时某地某个运动姿态作为可见状态，是一个三元组<时间，地点，姿态>，
其中姿态指的是我们通过设备获取的用户运动姿态（例如跑步、行走、行车等），时间和地点则是指设备获取到这个运动姿态时的地理位置和时间点，
显然这个三元组对于app开发者是可见的，而且这个三元组状态可以看作是由某个用户情景隐状态以一定概率触发产生。
具备了这些基本的元素后，将整个系统视作一个完整的隐马尔科夫链模型就十分合理了。

马尔科夫链
---
在说清楚隐马尔科夫模型前，首先要说明什么是马尔科夫链模型。仍以用户情景感知这个项目为例：
我们可以把s1，s2，…，st，…看作某个用户的情景信息，描述了该用户在时间维度上的行为变化，例如s1=shopping，s2=traveling，s3=working等等。显然这是一个随机过程，这里面每一个状态st都是随机的，而且对于真实世界中，状态st有可能和之前状态s1，s2，…，st-1相关，例如之前持续的工作学习类的行为会导致某个用户在之后更有可能发生一些娱乐休闲类的行为，再刻苦工作的人也需要休息。
为了简化问题，马尔科夫提出了一个简化的假设，即随机过程中各个状态st的概率分布只与它的前一个状态有关，简单的说st只受st-1的影响，P(st|s1,s2,s3,…,st-1)=P(st|st-1)。那么这个随机过程被称为马尔科夫过程或马尔科夫链。在马尔科夫链中，从一个状态si跳转到另一个状态sj的概率被称为转移概率aij，并且从一个状态跳转到别的状态的所有转移概率的和应为1。
我们可以想象马尔科夫链为一台机器，在确定一个初始状态后会不断的按照转移概率a开始工作，不断的输出新的状态，在工作了t个时间单位后，最后得到s1，s2，…，st这样一个状态序列。

隐马尔科夫链
---
现在的状况是，对于用户情景这样一类状态我们是并不知道的，虽然事实客观存在，只要是一个真实的用户，那么就一定会产生一系列的用户情景，但这些用户情景对于我们来说是不可见的状态。我们无法通过观察这样一个用户情景状态序列s1，s2，…，st-1来推测转移概率参数。
但是，上述用来描述用户某时某刻的某个运动姿态的三元组<时间，地点，姿态>却是可以通过用户随身携带的智能设备来获取，我称这种三元组状态为用户姿态，那么这由我们事先定义好的n种（v1，v2，…，vk，…，vn）用户姿态状态vk对于我们app开发者而言是可见的，虽然我们无法观测到用户情景这类“隐藏”状态，但是我们可以观测到用户姿态这类“可见”状态。
同时，我假设在t时刻，这类用户姿态是由t时刻下的用户情景状态wj(t)以一定概率激发出的可见状态vk(t)，这个概率记为bjk = P(vk(t)|wj(t))。
定义好了这些符号和参数后，隐马尔科夫链模型一般关注三类问题：
- 估值问题：给定一个模型，如何计算某个特定的输出序列概率（解法：前向算法）；
- 解码问题：给定一个模型和某个特定的输出序列，如何找到最可能产生这个输出的状态序列（解法：维比特算法）；
- 学习问题：给定足够量的观测数据，如何估计隐马尔科夫链模型的参数（解法：鲍姆韦尔奇算法，亦即前向后向算法）；
我们关心的问题是如何能够根据已有的用户姿态状态序列来判断用户当前处于哪个用户情景状态。这就需要我们拥有一个专属这个用户的隐含马尔科夫链模型，有了这个模型及对应的相关参数，我们可以预测用户下一时刻可能的用户情景状态。这属于一个典型的学习问题。
由上所述，我们可以形式化的定义这个待求的隐马尔科夫链模型：
这个隐马尔科夫链模型是一个三元组（π，A，B）。

    π = (πi) 初始化概率向量。
    A = (aij) 状态转移矩阵（P(xj(t)|xi(t-1))）
    B = (bjk) 混淆矩阵（Pr(vk|xj)）

前向后向算法
---
本质上，前向后向算法属于EM算法（广义期望最大化算法）的特例，而EM算法我们可以简单的理解为：根据现有的聚类结果，对所有数据重新进行划分。如果把最终得到的分类结果看做一个数学的模型，那么这些聚类的中心值，以及每一个点和聚类的隶属关系，可以看做这个模型的参数。然后根据重新划分的结果，得到新的聚类。这段描述引自吴军博士的《数学之美》，个人认为描述的简练精辟。用我自己的话来说，就是在一个初始模型的基础上，通过已有的数据来对这个模型进行反复迭代的修改，最终获得一个最理想的模型。
首先描述前向后向算法，有下面几个重要的概念：
- 前向变量：HMM在t时刻，位于隐状态si，且产生了可见序列前t个符号的概率，即

    αt(i) = P(v1,v2,…,vt,wt=si) \n
          = ∑i P(v1,v2,…,vt-1,wt-1=sj)*P(wt=si|wt-1=sj)*Pr(vt|wt=si) \n
          = ∑i αi(t-1) * aij * bik（v(t)）\n

- 后向变量：HMM在t时刻，位于隐状态si的条件下，产生了可见序列后t个符号的概率，即

    βt(i) = P(vt+1,vt+2,…,vT|wt=si)
          = ∑j P(vt+2,vt+3,…,vT|wt+1=sj)*P(wt+1=si|wt=sj)*Pr(vt+1|wt+1=sj)
          = ∑j βt+1(j)*aij*bjk（v(t+1)）

- γ变量：给定观察序列及隐马尔科夫链模型，定义t时刻位于隐藏状态Si的概率变量，即

    γt(i) = P(wt=si|v)
          = αt(i)*βt(i)/P(v)
          = αt(i)*βt(i)/∑i (αt(i)*βt(i))
    且保证∑i γt(i) = 1。

- ε变量：给定观察序列及隐马尔科夫链模型，定义t时刻位于隐藏状态Si以及t+1时刻位于隐藏状态Sj的概率变量，即

    εt(i,j) = P(wt=si,wt+1=sj|v)
            = αt(i)*aij*bjk（v(t+1)）*βt+1(i)/P(v)
            = αt(i)*aij*bjk（v(t+1)）*βt+1(i)/∑i∑j (αt(i)*aij*bjk（v(t+1)）*βt+1(i))
    且保证γt(i) = ∑j εt(i,j)。

如果对于时间轴t上的所有γt(i)相加，我们可以得到一个总和，它可以被解释为从其他隐藏状态访问Si的期望值（网格中的所有时间的期望），或者，如果我们求和时不包括时间轴上的t=T时刻，那么它可以被解释为从隐藏状态Si出发的状态转移期望值。相似地，如果对εt(i,j)在时间轴t上求和（从t=1到t=T-1），那么该和可以被解释为从状态Si到状态Sj的状态转移期望值。
根据上面的定义可以计算出重估的HMM模型参数。Baum及他的同事在70年代证明了上面的迭代过程一定是收敛的。因此如果我们迭代地的计算上面三个式子，由此不断地重新估计HMM的参数，那么在多次迭代后可以得到的HMM模型的一个最大似然估计。不过需要注意的是，前向后向算法所得的这个结果（最大似然估计）是一个局部最优解。

实现
---
现在有了整个隐马尔科夫链模型和相应的学习算法理论，我们来搭建用户情景感知项目的隐马尔科夫链模型：
该项目考虑使用python实现，其隐马尔科夫链模型主要包括以下几个元素：

    # 隐状态数目，由我们事先定义，这里我暂时选取几个作为举例：
    states = (‘Working, ‘Shopping’,’Exercising’,’Eatting’,’Traveling’,’Studying’)
    # 每个状态下可能的观察值，即可见状态：
    observations = {
        ‘TOI’: # 时间描述
        ‘POI’: # 地点描述
        ‘MotionType’: # 运动姿态描述
    }
    MotionType = (‘running’,’walking’,’sitting’,’driving’,’cycling’)
    # 初始状态空间的概率分布，每一项的初始概率都应该由数据统计得来
        start_probability = {
        ‘Working’=p1,
        ‘Shopping’=p2,
        ’Exercising’=p3,
        ’Eatting’=p4,
        ’Traveling’=p5,
        ’Studying’=p6
    }
    # 与时间无关的状态转移概率矩阵
    transition_probability = {
        ’ Working’: {‘Working’: a11, ‘Shopping’: a12, …},
        ’ Shopping’: {…},
        ’Exercising’={…},
        ’Eatting’={…},
        ’Traveling’={…},
        ’Studying’={…}
    }
    # 给定状态下，观察值概率分布,发射概率
    emission_probability = {
        …
    }
